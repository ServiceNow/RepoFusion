{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c29c738-685f-4179-a6fe-87848f145d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "050833ae-630b-4c05-858d-60e5e5fe4571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import transformers\n",
    "from torch.utils.data import DataLoader, RandomSampler, DistributedSampler, SequentialSampler\n",
    "import repo_training_codellm.FiD.src.data as src_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e9821aa-a2d6-42df-b9e2-d192a90d9311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/toolkit/code/'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to had been set to root of all code repos, like '/home/toolkit/code/'\n",
    "os.environ['PYTHONPATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7fd5c378-f9ec-48eb-a5cb-c31c6b09c6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = type(\"opt\", (object, ), {})()\n",
    "opt.passage_maxlength = 200\n",
    "opt.question_maxlength = 40\n",
    "opt.train_data = '/repo_data/open_domain_data/NQ/test.json'\n",
    "opt.n_context = 3\n",
    "opt.per_gpu_batch_size  = 2\n",
    "opt.is_distributed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed680874-20e0-4213-bb31-ceb2a1b4c4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46f370bb7aca42978a2887777fc1bb5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a05dcadc0f6e47c58514909f7f998d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41bb0ef39c2542f29dc8cb28cde23c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ce449dcad924e4bb5019d2107c73a43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = transformers.BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c7b9a4d-46c9-4393-ad94-798c5c845cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "collator_function = src_data.RetrieverCollator(\n",
    "    tokenizer, \n",
    "    passage_maxlength=opt.passage_maxlength, \n",
    "    question_maxlength=opt.question_maxlength\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b44c7784-7452-4ee0-a958-ccb004873eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = src_data.load_data(opt.train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8bfd59e0-1cdd-4bdc-8769-cc48cedf29c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3610"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "790e6820-4adc-4d65-94f3-0058d256fd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = src.data.Dataset(train_examples, opt.n_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ed606790-d574-4db9-be4c-df1a7ded76d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 0,\n",
       " 'question': 'question: who got the first nobel prize in physics',\n",
       " 'target': 'Wilhelm Conrad Röntgen </s>',\n",
       " 'passages': ['title: Nobel Prize in Physics context: Nobel Prize in Physics The Nobel Prize in Physics () is a yearly award given by the Royal Swedish Academy of Sciences for those who have made the most outstanding contributions for mankind in the field of physics. It is one of the five Nobel Prizes established by the will of Alfred Nobel in 1895 and awarded since 1901; the others being the Nobel Prize in Chemistry, Nobel Prize in Literature, Nobel Peace Prize, and Nobel Prize in Physiology or Medicine. The first Nobel Prize in Physics was awarded to physicist Wilhelm Röntgen in recognition of the extraordinary services he',\n",
       "  'title: Nobel Prize context: His son, George Paget Thomson, received the same prize in 1937 for showing that they also have the properties of waves. William Henry Bragg and his son, William Lawrence Bragg, shared the Physics Prize in 1915 for inventing the X-ray spectrometer. Niels Bohr was awarded the Physics prize in 1922, as was his son, Aage Bohr, in 1975. Manne Siegbahn, who received the Physics Prize in 1924, was the father of Kai Siegbahn, who received the Physics Prize in 1981. Hans von Euler-Chelpin, who received the Chemistry Prize in 1929, was the father of Ulf von Euler, who was awarded',\n",
       "  'title: Nobel Prize in Physics context: receive a diploma, a medal and a document confirming the prize amount. Nobel Prize in Physics The Nobel Prize in Physics () is a yearly award given by the Royal Swedish Academy of Sciences for those who have made the most outstanding contributions for mankind in the field of physics. It is one of the five Nobel Prizes established by the will of Alfred Nobel in 1895 and awarded since 1901; the others being the Nobel Prize in Chemistry, Nobel Prize in Literature, Nobel Peace Prize, and Nobel Prize in Physiology or Medicine. The first Nobel Prize in Physics was'],\n",
       " 'scores': tensor([1., 1., 1.])}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0497d8fb-9c90-4cb9-901e-7b3430a50bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = DistributedSampler(train_dataset) if opt.is_distributed else RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    sampler=train_sampler, \n",
    "    batch_size=opt.per_gpu_batch_size, \n",
    "    drop_last=True, \n",
    "    num_workers=0, \n",
    "    collate_fn=collator_function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6c6b2a6-07eb-443f-bc0b-912c8a31e50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toolkit/.conda/envs/rlctx_p39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# return (index, question_ids, question_mask, passage_ids, passage_masks, scores)\n",
    "batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0a4cf34a-66e9-43a3-a2f2-2e2f961a5bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = collator_function([train_dataset[0]] + [train_dataset[1]]+[train_dataset[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0eef2c29-e288-4597-a185-c86eb6198714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 200])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ccf6f0ff-cf0d-47c8-848f-3f62e2f043b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000, 1.0000],\n",
       "        [0.5000, 0.5000, 0.5000],\n",
       "        [0.3333, 0.3333, 0.3333]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1b785a1d-4e67-4a7f-b846-9ef53907a68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'question: who got the first nobel prize in physics'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b51eaa2e-a0f0-4d3e-a8b6-9aae13673dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'question: when is the next deadpool movie being released'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1]['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e268b4b5-2e83-4230-b297-c4e2b9114903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'question: which mode is used for short wave broadcast service'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[2]['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98892366-cfaa-4798-8cf6-0b9d3696be42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SeanDecker1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValeriyKnyazhev\n",
      "My-DIGI-ID\n",
      "CDZR0\n",
      "TreeZhiyuan\n",
      "slickqa\n",
      "VladRomanchuk\n",
      "baishuo\n",
      "david2999999\n",
      "eddiewgj\n",
      "JDode\n",
      "android-little-boy\n",
      "leshiv\n",
      "zli78122\n",
      "kenichi-ando\n",
      "sistcoop\n",
      "DieguinhoHR\n",
      "smallxiongxiong\n",
      "DeyanZhelyazkov\n",
      "wuxinlingluan\n",
      "java-ea\n",
      "opentok\n",
      "MFunction96\n",
      "MfromAzeroth\n",
      "jannal\n",
      "google\n",
      "pengcash\n",
      "FLxmw\n",
      "akash-coded\n",
      "tacticalrce\n",
      "ot-maksim\n",
      "DwArFeng\n",
      "ToreAad\n",
      "fengpod\n",
      "dongjihui666\n",
      "Manolomon\n",
      "mariodavid\n",
      "AvaN0x\n",
      "HRI-EU\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "from generate_hole_and_rule_contexts_mod import get_hole_context, get_default_prompt\n",
    "from transformers import GPT2TokenizerFast\n",
    "from context import *\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "\n",
    "\n",
    "base_dir = '/repo_data/repo_preprocessed_data/'\n",
    "split = 'train'\n",
    "\n",
    "def create_file_line_char_mapping(repo):\n",
    "    file_line_char_mapping = {}\n",
    "    data = pickle.load(open(os.path.join(base_dir, split, repo, 'hole_data'), 'rb'))\n",
    "    for k, v in data.items():\n",
    "        for (l, c) in v:\n",
    "            key = k + '_' + str(l)\n",
    "            file_line_char_mapping[key] = c\n",
    "    return file_line_char_mapping\n",
    "\n",
    "def get_file_and_hole_pos(hole):\n",
    "    hole_parts = hole.split('/')[-1].split('_')\n",
    "    if len(hole_parts) > 3:\n",
    "        new_hole_parts = hole_parts[:-2]\n",
    "        filename = '_'.join(new_hole_parts)\n",
    "        filename = [filename]\n",
    "    else:\n",
    "        filename = [hole_parts[0]]\n",
    "    file = '/'.join(hole.split('/')[:-1] + filename)\n",
    "    pos = (int(hole_parts[-2]), int(hole_parts[-1]))\n",
    "    return file, pos\n",
    "    \n",
    "\n",
    "repos = os.listdir(os.path.join(base_dir, 'medium_' + split))\n",
    "for repo in repos:\n",
    "    print(repo)\n",
    "    file_line_char_mapping = create_file_line_char_mapping(repo)\n",
    "    f_out = open(os.path.join(base_dir, 'medium_' + split, repo, \"char_hole_and_rule_contexts.json\"), \"w\")\n",
    "    lines = open(os.path.join(base_dir, 'medium_' + split, repo, 'hole_and_rule_contexts.json')).readlines()\n",
    "    assert len(lines) <= 10000\n",
    "    for line in lines:\n",
    "        entry = json.loads(line)\n",
    "        hole_id = entry['id']\n",
    "        file_name, hole_pos = get_file_and_hole_pos(hole_id)\n",
    "        hole_line = hole_pos[0]\n",
    "        line_char = file_line_char_mapping[file_name + '_' + str(hole_line)]\n",
    "        new_hole_pos = (hole_line, line_char)\n",
    "        entry['id'] = file_name + '_' + str(new_hole_pos[0]) + '_' + str(new_hole_pos[1])\n",
    "        hole_context, target = get_hole_context(file_name, new_hole_pos)\n",
    "        entry['question'] = hole_context\n",
    "        entry['target'] = target\n",
    "        entry['answers'] = [target]\n",
    "        default_context_obj = getContext(context_location='in_file',\n",
    "                                tokenizer=tokenizer,\n",
    "                                file=file_name,\n",
    "                                context_len=4072,\n",
    "                                context_scope='pre',\\\n",
    "                                context_type='lines',\\\n",
    "                                top_k=-1)\n",
    "        entry['ctxs'][16]['text']=get_default_prompt(new_hole_pos, default_context_obj)\n",
    "        f_out.write(json.dumps(entry))\n",
    "        f_out.write(\"\\n\")\n",
    "        f_out.flush()\n",
    "    f_out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('repo_training')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "49e378f172a8b46bf57800d0ac0bac4fc1e6ce253c9f8cab86c0c50488e70be3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
