# Data preparation params
filename_1K_20plus_file_list: /data/hf_repos/the-stak-repo-level/meta_data/java/1K_20plus_file_list.parquet
filename_the_stack11_dedup_alt_comments: /data/christmas_datasets/the_stack_dedup_alt_comments.jsonl
path_java_filtered: /repo_data/the_stack11_dedup_alt_comments_no_1K_set/data
path_java_filtered_subset: /repo_data/the_stack11_dedup_alt_comments_no_1K_set_subset/data
path_java_filtered_subset_pivots: /repo_data/the_stack11_dedup_alt_comments_no_1K_set_subset/pivots
repo_names_rand_seq_filename: /repo_data/the_stack11_dedup_alt_comments_no_1K_set_subset/repo_names_rand_seq.json
splits_filename: /repo_data/the_stack11_dedup_alt_comments_no_1K_set_subset/splits_repo_names.json
regenerate_repo_names_rand_seq: False
min_file_count_per_repo: 20
pivots_per_file: 10
max_pivots_per_repository: 10000
bucket_size: 400000
train_size: 300000
validation_size: 100000
test_size: 100000
num_proc: 8
seed: 42

# Model params
base_model_name: Salesforce/codet5-base
trained_model_name: codet5-base-ntp-java
experiment_name: tests
model_dir_base: /repo_data/finetuning_checkpoints
evaluation_strategy: "steps"
eval_steps: 100
predict_with_generate: True
include_inputs_for_metrics: True
logging_strategy: steps
logging_steps: 100
save_strategy: steps
save_steps: 200
save_total_limit: 3
num_train_epochs: 1
fp16: True
report_to: tensorboard
dataloader_num_workers: 4

append_special_token_to_input:

min_encoder_seq_length: 0
min_decoder_seq_length: 0
encoder_seq_length: 512
decoder_seq_length: 512

# if wold have been perfect 4e-6 and several epochs
per_device_train_batch_size: 8
per_device_eval_batch_size: 8
learning_rate: 4.0e-5 
warmup_steps: 100
weight_decay: 0.01
