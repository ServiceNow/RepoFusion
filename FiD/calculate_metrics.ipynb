{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The code to evaluate EM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codet5base-2048_pretrained_True: 9016/310703, EM=2.90180654837578\n",
      "codet5base-512_pretrained_True: 2956/167737, EM=1.7622826210078872\n",
      "codet5large-2048_pretrained_True: 10649/255611, EM=4.16609613827261\n",
      "codet5large-512_pretrained_True: 3860/167737, EM=2.301221555172681\n",
      "FID-codet5base-512-63_no-truncation-codex-last_True: 134827/271060, EM=49.740647827049365\n",
      "FID-codet5base-768-32_no-truncation-direct_True: 83711/167737, EM=49.90610300649231\n",
      "finetuned-codet5base-512_baseline_True: 20499/167737, EM=12.220917269296578\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def em_code(prediction, ground_truth):\n",
    "    gt = ground_truth.rstrip()\n",
    "    lines = prediction.splitlines()\n",
    "    if len(lines) == 0:\n",
    "        if gt == \"\":\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    pred = lines[0].rstrip()\n",
    "    return pred == gt\n",
    "    \n",
    "base_dir = '/repo_data/repo_FID/old_medium_split_evaluation/'\n",
    "experiments = os.listdir(base_dir)\n",
    "for exp in experiments:\n",
    "    success = 0\n",
    "    total = 0\n",
    "    result_file = os.path.join(base_dir, exp, 'final_output.jsonl')\n",
    "    if os.path.exists(result_file):\n",
    "        with open(result_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            for entry in data:\n",
    "                if em_code(entry['prediction'], entry['target']):\n",
    "                    success += 1\n",
    "                total += 1\n",
    "        print(f\"{exp}: {success}/{total}, EM={success*100/total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48838/167737, EM=29.115818215420568\n"
     ]
    }
   ],
   "source": [
    "file_path = '/repo_data/finetuning_checkpoints/codet5-base-ntp-java/eval_cp251000_tAll_vAll_sl512_nep1_bspd32_dn2_graccs2_lr1e-4_wup100_wd005_disha_data_2/examples/0_1.json'\n",
    "total=0\n",
    "success=0\n",
    "with open(file_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "    for entry in data['first_line']:\n",
    "        if em_code(entry['prediction'], entry['label']):\n",
    "            success += 1\n",
    "        total += 1\n",
    "print(f\"{success}/{total}, EM={success*100/total}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing truncation from left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toolkit/.conda/envs/repo_training/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Keyword arguments {'truncation_side': 'left'} not recognized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  1, 482,   2])\n",
      "<s>public</s>\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "model_name = 'Salesforce/codet5-base'\n",
    "tokenizer = transformers.RobertaTokenizer.from_pretrained(model_name)\n",
    "\n",
    "input = \"public static void main \"\n",
    "tokens = tokenizer(input, \\\n",
    "                    max_length=3, \\\n",
    "                    padding='max_length', \\\n",
    "                    return_tensors=\"pt\", \\\n",
    "                    truncation=True, \\\n",
    "                    truncation_side='left',)\n",
    "print(tokens['input_ids'][0])\n",
    "print(tokenizer.decode(tokens['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 1, 'text': 'public static void main'}, {'title': 2, 'text': '[] args) {'}, {'title': 3, 'text': 'Hello World\");}'}]\n"
     ]
    }
   ],
   "source": [
    "def truncate_from_left(text, text_maxlen):\n",
    "    tokens = tokenizer(text, truncation=False).input_ids\n",
    "    if len(tokens) > text_maxlen:\n",
    "        tokens = tokens[-text_maxlen:]\n",
    "    return tokenizer.decode(tokens, skip_special_tokens=True)\n",
    "        \n",
    "contexts = [{'title':1, 'text':'public static void main'},\\\n",
    "            {'title': 2, 'text':'public static void main(String[] args) {'},\\\n",
    "            {'title': 3, 'text':'public static void main(String[] args) {System.out.println(\"Hello World\");}'}]\n",
    "\n",
    "for context in contexts:\n",
    "    context['text'] = truncate_from_left(context['text'], 5)\n",
    "print(contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rule_name: 1 rule_context: public static void main', 'rule_name: 2 rule_context: public static void main(String[] args) {', 'rule_name: 3 rule_context: public static void main(String[] args) {System.out.println(\"Hello World\");}']\n"
     ]
    }
   ],
   "source": [
    "contexts = [{'title':1, 'text':'public static void main'}, \\\n",
    "    {'title': 2, 'text':'public static void main(String[] args) {'}, \\\n",
    "        {'title': 3, 'text':'public static void main(String[] args) {System.out.println(\"Hello World\");}'}]\n",
    "f = \"rule_name:\" + \" {} \" + \"rule_context:\" + \" {}\"   \n",
    "passages = [f.format(c['title'], c['text']) for c in contexts]\n",
    "print(passages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('repo_training': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49e378f172a8b46bf57800d0ac0bac4fc1e6ce253c9f8cab86c0c50488e70be3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
